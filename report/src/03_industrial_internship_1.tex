\documentclass[../00_main.tex]{subfiles}

\begin{document}

\section{Industrial Internship}

\subsection{NASA Earthdata}

\subsubsection{Registration}

To access data on the NASA Earthdata platform (which includes GES DISC),
a registered account is required. The purpose of the registration is for NASA
to improve their service and to offer notifications and saved preferences.
% cite https://wiki.earthdata.nasa.gov/display/EL/Earthdata+Login+Overview+and+Policy%2C+v1.2
The Earthdata account then needs to be linked to a GES DISC account to access
the M2I3NPASM dataset I am working with. A full guide can be found under 
\href{https://www.unidata.ucar.edu/software/netcdf/}{this url}.
% cite this too

\subsubsection{Downloading}

To actually download GES DISC Data there are many options, but \texttt{wget}
might be preferable. \texttt{wget} is a utility for downloading files from the
internet. It is generally used as a command line tool and it is available for
most platforms. The steps necessary to set up wget to download data from GES
DISC are outlined 
\href{https://disc.gsfc.nasa.gov/data-access#mac_linux_wget}{here}. The process
simply involves setting up your login information in a local file. Then, one
needs to acquire the urls that point to the data that is meant to be
downloaded. As described above in the section on NASA remote sensing data,
% TODO: reference previous section
a subset of the dataset (e.g. M2I3NPASM) should be specified to significantly
reduce the download time. Then the GES DISC website will provide one or more
download links, generally in a \texttt{txt} file. This file can then be given
to \texttt{wget} (following the platform-specific instructions) to download
these files. Once the files have been downloaded, they are ready to be
analyzed. 

\subsection{Python Application Development}

This subsection is based on the notes in my internship diary and will explain
the process of developing the Python application. It will not go into great
technical detail because I want to reserve that for the description of the
finished program. Additionally, every program written during my internship
contributed to the final program and thus when I describe the final result
I will be indirectly describing the important results obtained along the way. 
The decision to work with
Python was made in our first meeting and we chose it because everyone had had
at least some experience with it and Python has a rich ecosystem of libraries
that would enable us to complete all the parts of our assignment.\newline

\subsubsection{Simple Beginnings -- 10.09. to 20.09.}

% TODO: cite the documentation of these things

The first step was to download the netCDF data from the GES DISC website to
start working with it. I created the required account (as outlined above) and 
% TODO: reference the section
downloaded 3 days worth of data of the M2I3NPASM dataset using \texttt{wget}.
Then, I develped a simple command line python program that enabled me to more
comfortably download large quantities of files. This program used the Python
requests library to download the files, and not \texttt{wget}. This program has
since been retired because \texttt{wget} is completely sufficient and there is
no need for this program. \newline
% cite the requests documentation
The next simple command line program I wrote listed all the available variables
in a netCDF file. This was the first time I worked with these files and thus
I had to find out how it works. I chose the \texttt{netCDF4} Python library for
this task because it is developed by the same group that created the file
format itself. I also had to find out how to access the variable names that are
stored in a netCDF file.\newline
Once I had familiarized myself with the file format, I wrote a simple program 
capable of creating a heat map graph of a data type that only has latitude and
longitude dimensions. This program was not flexible and most values were
hard-coded, but I forced me to explore how to plot two--dimensional heat maps
using Python. I used the \texttt{matplotlib} library to create the plot itself
and to save it as a picture. To create the map features I used the
\texttt{cartopy} library which specializes in creating all kinds of maps.

\subsubsection{Figuring out Data Storage -- 22.09. to 01.10.}

Because M2I3NPASM data comes in 1 file per day it can be cumbersome to work
with data that covers more than a single day (many files would have to managed
at once). Furthermore, each file includes multiple variables (because one
generally does not know which specific variable will be needed) which means
that there is unnecessary data once one decides to analyze a single variable.
To solve both of these issues, my supervisor suggested that I extract one
particular variable from multiple netCDF files and save all the data into
a single file. Now a file format for these files needed to be found.\\
The data in netCDF files is stored in multi-dimensional arrays because this
structures resembles the structure of the data most closely. Thus our data
format should also support multi-dimensional arrays. After
considering multiple alternative options (Parquet, HDF5, netCDF), with my
supervisor's advice I decided on NPZ files, a format for the \texttt{numpy} 
Python library. This format is convenient because \texttt{numpy} is one of the 
most popular scientific python computing libraries and used as a backend for 
many other libraries meaning that it is widely usable. Also, NPZ files natively
support multi-dimensional arrays which makes them a good fit for our data. 
The compression of NPZ files is another advantage because it saves space when 
the file becomes large. NPZ files were chosen over NPY files, which are also 
files used by the \texttt{numpy} library, because NPY files are not compressed 
and thus take up more space. NPY files also only hold one single
multi-dimensional array while NPZ files can hold multiple arrays. This enables
me to store all the necessary data in a single file (the actual data plus data
for the dimensions time, latitude, longitude, level).\\
Unfortunately NPZ files are not self-describing and cannot hold information
about the data that they contain. To not lose the information about our data
that the netCDF files hold, another file type to store this information was
required. For this purpose I chose JSON files, which can easily be read from
and written to using Python and most other programming languages. Conveniently,
the Python dictionary data type -- a list if key-value pairs, e.g. \texttt{"age":
21} where \texttt{"age"} is the key and \texttt{21} is the value -- can be easily
converted to JSON and stored for later use. This is the approach I decided to
implement.\\
After choosing these files types, I started to develop a program that would
take every netCDF file in a directory and take the data of one variable from
each file and put it into one large multi-dimensional array. It also extracts
the values for the latitude and longitude as well as the start time of the
first file and the end time of the last file. The data, latitude, and longitude
are then saved to a single NPZ file. Then the important metadata -- the minimum
and maximum values of data and dimensions, start and end time, measurement
intervals, units, variable names -- are extracted, put into a Python
dictionary, and then saved as a JSON file.
% TODO: cite documentation
% TODO: explain numpy

\subsubsection{Improving the Data Extraction and Plotting -- 07.10. to
21.10.2020}

After both basic versions of a heat map plotting program and a data extraction
program were developed, I worked on making them work together and
iteratively improving them.

\paragraph{Data Processing.}

When the processed data was first being used in plotting some bugs became
apparent. The most severe of these was a mistake I made in handling the masked
arrays contained in the netCDF files. These arrays contain data which might not
be valid for certain values of the dimensions. In the netCDF files all of these
values are filled with a special value called the \texttt{\_FillValue}. This
value is specified in the netCDF files and can be used to process the files
correctly. If it is not handled correctly, the fill value will be interpreted
as a proper value and make any plot unusable. What I did to fix this issue was
to replace every occurrence of the fill value with the \texttt{numpy} data type
\texttt{numpy.NaN} (a specfic value meaning Not a Number). This makes it simple
to ignore these values in calculations because there can be no confusion about
whether or not the numbers are valid. The fill value is also being saved to the
metadata file so that it can be used at a late date.

\paragraph{Plotting.}

The main changes to the plotting program in this part of the development was
the creation of a program that can plot time series, unifying the heat map and
time series plotting program, and enabling the plotting programs to work with
the above mentioned \texttt{numpy.NaN} values.\\
To plot a time series one has to select data for a specific point in space and
then plot all the values of that point from a start date and time to an end
date and time. The most challenging element here is the conversion of
a user-entered date and time in the format \texttt{YYYY-MM-DD H} to
a computer-readable date and time object and then to an array index that can be
used to access the data. This was achieved by reading in the user-specified
date and time as text, using a Python standard library function to convert it
into a \texttt{datetime} data type. Then one can find the difference between
the user-specified date and time and the start date and time of the data which
can then be used to find the index of the array that corresponds to the given
time. \\
Unifying the heat map and time series plotting involved copying the code of
both programs to a single file and then setting up the command line program to
accept the types of input required to plot each of the types of plots.\\
To get the plotting programs to work with \texttt{numpy.NaN} values, the only
change I had to make to the programs was to change the functions that find the
minimum and maximum values to functions that ignore \texttt{numpy.NaN} values.
If this is not done, any operation involving a \texttt{NaN} value will itself
result in \texttt{NaN}. Now the \texttt{NaN} values are left out of
computations and will not invalidate the results.

\subsubsection{Starting a GUI -- 22.10. to 30.10.}


\end{document}
